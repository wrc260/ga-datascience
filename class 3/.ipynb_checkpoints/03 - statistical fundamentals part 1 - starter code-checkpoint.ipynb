{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 3: Statistical Fundamentals (Part 1)\n",
    "## Starter code for guided practice & demos\n",
    "Topics covered:\n",
    "\n",
    "#### 1. Codealong: Summary statistics in pandas\n",
    "- Basic stats (min, max, mean, median, mode, count)\n",
    "- Box plots (interquartile range, quantiles, outliers)\n",
    "- Standard deviation, variance, pandas.describe()\n",
    "- Correlation\n",
    "- Anscombe's Quartet\n",
    "\n",
    "#### 2. Demo: Median & mean\n",
    "- Generating random data using statistical distributions\n",
    "- Density plots using matplotlib\n",
    "\n",
    "#### 3. Demo: Skewness & kurtosis\n",
    "- Normality\n",
    "- Random seeds\n",
    "\n",
    "#### 4. Demo: Types of distribution\n",
    "\n",
    "#### 5. Demo: Dummy variables\n",
    "- Using masks to randomly divide a dataset into two categories (useful later when we talk about cross-validation)\n",
    "- Using maps to code categorical variables as numeric\n",
    "- Using dummy variables to code a single categorical variable of k categories as k-1 dummy variables using `pd.get_dummies()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background-color: #fcf2f2; border-color: #dFb5b4; border-left: 5px solid #dfb5b4; padding: 0.5em;'>\n",
    "**Warning:** You will need to install ggplot before you run the next cell (run `conda install ggplot` in your shell/Terminal).\n",
    "<div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import the modules we'll be using today\n",
    "from ggplot import mtcars\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Codealong: Summary statistics in pandas\n",
    "\t\n",
    "Methods available include:\n",
    "\n",
    "    .min() - Compute minimum value\n",
    "    .max() - Compute maximum value\n",
    "    .mean() - Compute mean value\n",
    "    .median() - Compute median value\n",
    "    .mode() - Compute mode value(s)\n",
    "    .count() - Count the number of observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1. Basic stats\n",
    "#### Read in the examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example1</th>\n",
       "      <th>example2</th>\n",
       "      <th>example3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>75</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>87</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>49</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>68</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>75</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16</td>\n",
       "      <td>84</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>29</td>\n",
       "      <td>98</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>18</td>\n",
       "      <td>92</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   example1  example2  example3\n",
       "0        18        75        55\n",
       "1        24        87        47\n",
       "2        17        49        38\n",
       "3        21        68        66\n",
       "4        24        75        56\n",
       "5        16        84        64\n",
       "6        29        98        44\n",
       "7        18        92        39"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is one way of creating a dataframe, by specifying a dictionary of lists\n",
    "df = pd.DataFrame({\n",
    "    'example1': [18, 24, 17, 21, 24, 16, 29, 18],\n",
    "    'example2': [75, 87, 49, 68, 75, 84, 98, 92],\n",
    "    'example3': [55, 47, 38, 66, 56, 64, 44, 39]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instructor example: Calculate the mean for each coloumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "example1    20.875\n",
       "example2    78.500\n",
       "example3    51.125\n",
       "dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "example1    19.5\n",
       "example2    79.5\n",
       "example3    51.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example1</th>\n",
       "      <th>example2</th>\n",
       "      <th>example3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>75.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   example1  example2  example3\n",
       "0        18      75.0       NaN\n",
       "1        24       NaN       NaN"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Students: Calculate median, mode, max, min for example\n",
    "\n",
    "Note: All answers should match your hand calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2. Quartiles, interquartile range and box plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instructor: Interquartile range "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"50% Quartile:\"\n",
    "print df.quantile(.50)\n",
    "print\n",
    "\n",
    "print \"Median (red line of a box plot)\"\n",
    "print df.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print\"25% (bottom of the box)\"\n",
    "print df.quantile(0.25)\n",
    "print\n",
    "\n",
    "print\"75% (top of the box)\"\n",
    "print df.quantile(0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['example1'].plot(kind='box')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Student: Create plots for examples 2 and 3 and check the quartiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What does the cross in example 2 represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3. Standard deviation and variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In Pandas\n",
    "\tMethods include: \n",
    "\t\t.std() - Compute Standard Deviation\n",
    "\t\t.var() - Compute variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's calculate variance by hand first.\n",
    "\n",
    "<img(src='https://dl.dropboxusercontent.com/u/3404204/samplevarstd.png', style=\"width: 50%; height: 50%\")>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# example1\n",
    "mean = df[\"example1\"].mean()\n",
    "n= df[\"example1\"].count()\n",
    "\n",
    "print \"example1:\"\n",
    "print df[\"example1\"], \"\\n\"\n",
    "\n",
    "print \"mean:\", mean, \"\\n\"\n",
    "print \"n:\", n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Written out by hand for instructional purposes \n",
    "# If you have time, try refactoring this to create a function to calculate variance for any dataset\n",
    "\n",
    "# Find the squared distance from the mean\n",
    "obs0 = (18 - mean) ** 2\n",
    "obs1 = (24 - mean) ** 2\n",
    "obs2 = (17 - mean) ** 2\n",
    "obs3 = (21 - mean) ** 2\n",
    "obs4 = (24 - mean) ** 2\n",
    "obs5 = (16 - mean) ** 2\n",
    "obs6 = (29 - mean) ** 2\n",
    "obs7 = (18 - mean) ** 2\n",
    "\n",
    "print obs0, obs1, obs2, obs3, obs4, obs5, obs6, obs7\n",
    "print\n",
    "\n",
    "# Sum each observation's squared distance from the mean \n",
    "numerator = obs0 + obs1 + obs2 + obs3 + obs4 + obs5 + obs6 +obs7\n",
    "denominator = n - 1\n",
    "variance = numerator/denominator\n",
    "print \"numerator:\", numerator, \"\\n\"\n",
    "print \"denominator:\", denominator, \"\\n\"\n",
    "print \"variance:\", variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Using pandas\n",
    "print \"Variance\"\n",
    "print df[\"example1\"].var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Students: Calculate the standard deviation for each sample\n",
    "\n",
    "Recall that the standard deviation is the square root of the variance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find the variance for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate standard deviation by hand from the variance of each dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now do it with pandas!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Short Cut!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We can use describe() method to do lots of things at once:\n",
    "# gives us count of non-missing values, mean, std dev, min/max + quartiles\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Student: Check understanding \n",
    "Which value in the above table is the median? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4. Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Correlations between example1, example2, and example3 as a correlation matrix\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's explore this dataset\n",
    "anscombe = pd.read_csv('anscombe.csv')\n",
    "anscombe = anscombe.drop('Unnamed: 0', axis=1)  # bit of data munging, we don't need this column so drop it\n",
    "anscombe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Huh, this looks like a weird dataset. Two x columns, four y columns...let's get some more intuition about it\n",
    "# by looking at the aggregate statistics. Before you read on, what do you notice?\n",
    "anscombe.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When looking at the dataframe, the data looks quite different, but when looking at the output from the `.describe()` call, we notice the columns share some similar features:\n",
    "- mean(x) = 9, i.e. both x cols have mean of 9\n",
    "- var(x) = 11, i.e. both x cols have variance of 11 (std dev = sqrt(11) = 3.316625)\n",
    "- mean(y) = 7.50, i.e. all y columns have mean of 7.50 (or close to it)\n",
    "- var(y) = 4.12, i.e. all y columns have variance of 4.12 (std dev = sqrt(4.12) = ~2.03)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's check out the correlation matrix to try understand this dataset further\n",
    "anscombe.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we were to plot x with y1, y2 and y3; and plot x4 with y4...what can we expect? Well maybe we could look at the correlations of these plots, as well as a fitted line of best fit (a.k.a \"linear regression\") for each of those:\n",
    "- corr(x, y) = 0.816 for all plots mentioned above\n",
    "- linear regression for all plots is `y = 3 + 0.5*x`\n",
    "\n",
    "From inspecting summary statistics, these look pretty identical. Let's now visualise and inspect further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualise\n",
    "for y in ['y1', 'y2', 'y3', 'y4']:\n",
    "    if y != 'y4':\n",
    "        print anscombe.plot(kind='scatter', x='x', y=y)\n",
    "    else:\n",
    "        print anscombe.plot(kind='scatter', x='x4', y=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualising is critical sometimes! Even though ALL four of above plots have equal mean, equal variance, equal correlation, equal regression coefficients...\n",
    "- `x ~ y1` has a reasonable if slightly noisy relationship between x & y1\n",
    "- `x ~ y2` has a perfect non-linear (i.e. not a line, i.e. parabolic) relationship between x & y2\n",
    "- `x ~ y3` has a perfect linear relationship between x & y3, except for one outlier\n",
    "- `x4 ~ y4` has no relationship between x4 & y4, other than all the x's are 8 except for one rogue point!\n",
    "\n",
    "These graphs were created in 1973 by statistician Francis Anscombe to demonstrate the importance of graphing data before analyzing it. Read more here: https://en.wikipedia.org/wiki/Anscombe%27s_quartet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Demo: Mean & median\n",
    "\n",
    "Although the mean and median both give us some sense of the centre of a distribution, they aren't always the same. The *median* gives us a value that **splits the data into two halves** while the *mean* is a **numeric average,** so extreme values can have a significant impact on the mean. \n",
    "\n",
    "In a symmetric distribution, the mean and median will be the same. Let's investigate with a density plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First, we'll use a \"random seed\" to ensure your randomly generated numbers are the same as mine\n",
    "np.random.seed(12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bunch_of_random_but_normally_distributed_numbers = np.random.normal(size=100000)\n",
    "norm_data = pd.DataFrame(bunch_of_random_but_normally_distributed_numbers)\n",
    "norm_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualise\n",
    "norm_data.plot(kind=\"density\", figsize=(10,5))\n",
    "\n",
    "plt.vlines(norm_data.mean(),     # Plot black line at mean\n",
    "           ymin=0, \n",
    "           ymax=0.4,\n",
    "           linewidth=5.0)\n",
    "\n",
    "plt.vlines(norm_data.median(),   # Plot red line at median\n",
    "           ymin=0, \n",
    "           ymax=0.4, \n",
    "           linewidth=2.0,\n",
    "           color=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the plot above, the mean and median are both so close to zero that the red median line lies on top of the thicker black line drawn at the mean. \n",
    "\n",
    "In skewed distributions, the mean tends to get pulled in the direction of the skew, while the median tends to resist the effects of skew:\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate skewed data from an exponential distribution\n",
    "skewed_data = pd.DataFrame(np.random.exponential(size=100000))\n",
    "skewed_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "skewed_data.plot(kind=\"density\", figsize=(10,5), xlim=(-1,5))\n",
    "\n",
    "plt.vlines(skewed_data.mean(),     # Plot black line at mean\n",
    "           ymin=0, \n",
    "           ymax=0.8,\n",
    "           linewidth=5.0)\n",
    "\n",
    "plt.vlines(skewed_data.median(),   # Plot red line at median\n",
    "           ymin=0, \n",
    "           ymax=0.8, \n",
    "           linewidth=2.0,\n",
    "           color=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the mean is also influenced heavily by outliers, while the median resists the influence of outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "norm_data = np.random.normal(size=50)\n",
    "some_outliers = np.random.normal(15, size=3)\n",
    "combined_data = pd.DataFrame(np.concatenate((norm_data, some_outliers), axis=0))\n",
    "\n",
    "combined_data.plot(kind=\"density\", figsize=(10,5), xlim=(-5,20))\n",
    "\n",
    "plt.vlines(combined_data.mean(),     # Plot black line at mean\n",
    "           ymin=0, \n",
    "           ymax=0.2,\n",
    "           linewidth=5.0)\n",
    "\n",
    "plt.vlines(combined_data.median(),   # Plot red line at median\n",
    "           ymin=0, \n",
    "           ymax=0.2, \n",
    "           linewidth=2.0,\n",
    "\n",
    "           color=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the median tends to resist the effects of skewness and outliers, it is known a \"robust\" statistic. \n",
    "\n",
    "The median generally gives a better sense of the typical value in a distribution with significant skew or outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Demo: Skewness and Kurtosis\n",
    "*Skewness* measures the **skew or asymmetry of a distribution** while *Kurtosis* measures the **\"peakedness\" of a distribution**. \n",
    "\n",
    "We won't go into the exact calculations behind these, but they are essentially just statistics that take the idea of variance a step further: while variance involves squaring deviations from the mean, skewness involves cubing deviations from the mean, and kurtosis involves raising deviations from the mean to the 4th power.\n",
    "\n",
    "Pandas has built in functions for checking skewness and kurtosis, df.skew() and df.kurt() respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comp1 = np.random.normal(loc=0, scale=1, size=200) # N(0, 1)\n",
    "comp2 = np.random.normal(loc=10, scale=2, size=200) # N(10, 4)\n",
    "\n",
    "df1 = pd.Series(comp1)\n",
    "df2 = pd.Series(comp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"N(0,1) with 200 variates:\\t\\t\", df1.skew()  # Normal distribution therefore skew is close to zero\n",
    "print \"N(10,2) with 200 variates:\\t\\t\", df2.skew()  # Normal distribution therefore skew is close to zero\n",
    "print \"exponential(1.0) with 100k variates:\\t\", skewed_data.skew()[0]  # Positively skewed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"N(0,1) with 200 variates:\\t\\t\", df1.kurt()  # N(0,1) distribution, kurtosis is close to zero\n",
    "print \"N(10,2) with 200 variates:\\t\\t\", df2.kurt()  # N(10,4) distribution is flatter than N(0,1), therefore lower kurtosis\n",
    "print \"exponential(1.0) with 100k variates:\\t\", skewed_data.kurt()[0]  # Skewed & peaked, should have higher kurtosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: mtcars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's now use an example dataset (mtcars) from the ggplot library\n",
    "mtcars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mtcars['mpg'].plot(kind=\"density\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mtcars[\"mpg\"].describe()  # Check out basic stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mtcars[\"mpg\"].skew()  # Check skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mtcars[\"mpg\"].kurt()  # Check kurtosis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Demo: Types of distribution\n",
    "To explore these measures further, let's create some dummy data and inspect it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "norm_data = np.random.normal(size=100000)\n",
    "skewed_data = np.concatenate((np.random.normal(size=35000) + 2, \n",
    "                              np.random.exponential(size=65000)), \n",
    "                              axis=0)\n",
    "uniform_data = np.random.uniform(0, 2, size=100000)\n",
    "peaked_data = np.concatenate((np.random.exponential(size=50000),\n",
    "                              np.random.exponential(size=50000) * (-1)),\n",
    "                              axis=0)\n",
    "\n",
    "data_df = pd.DataFrame({\"norm\": norm_data,\n",
    "                        \"skewed\": skewed_data,\n",
    "                        \"uniform\": uniform_data,\n",
    "                        \"peaked\": peaked_data})\n",
    "\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualise the normal distribution\n",
    "data_df[\"norm\"].plot(kind=\"density\", xlim=(-5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualise the peaked distribution (two exponentials back to back)\n",
    "data_df[\"peaked\"].plot(kind=\"density\", xlim=(-5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualise the skewed distribution (normal with a bit of exponential)\n",
    "data_df[\"skewed\"].plot(kind=\"density\", xlim=(-5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualise the uniform distribution\n",
    "data_df[\"uniform\"].plot(kind=\"density\", xlim=(-5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We can visualise all the columns of the dataframe (i.e. all the distributions) in one go\n",
    "data_df.plot(kind=\"density\", xlim=(-5,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skewness\n",
    "Now let's check the skewness of each of these distributions. \n",
    "\n",
    "Since skewness measures asymmetry, we'd expect to see low skewness for all of the distributions except the skewed one, because all the others are roughly symmetric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_df.skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kurtosis\n",
    "Now let's check kurtosis. Since kurtosis measures peakedness, we'd expect the flat (uniform) distribution to have low kurtosis while the distributions with sharper peaks should have higher kurtosis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_df.kurt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the output, the normally distributed data has a kurtosis near zero, the flat distribution has negative kurtosis, and the two pointier distributions have positive kurtosis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Demo: Dummy variables\n",
    "We want to represent categorical variables numerically, but we can't simply code them as 0=rural, 1=suburban, 2=urban because that would imply an **ordered relationship** between suburban and urban (suggesting that urban is somehow \"twice\" the suburban category, which doesn't make sense).\n",
    "\n",
    "Why do we only need **two dummy variables, not three?** Because two dummies capture all of the information about the Area feature, and implicitly defines rural as the reference level.\n",
    "\n",
    "In general, if you have a categorical feature with k levels, you create k-1 dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read data into a DataFrame\n",
    "data = pd.read_csv('advertising.csv', index_col=0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummying categorical variables with two categories\n",
    "Let's create a new feature called \"Size,\" and randomly assign observations to be small or large:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reset random seed for reproducibility\n",
    "np.random.seed(12345)\n",
    "\n",
    "# Create a Series of booleans in which roughly half are True\n",
    "nums = np.random.rand(100)\n",
    "mask_large = nums > 0.5\n",
    "\n",
    "print \"nums:\", nums[0:6]\n",
    "print \"mask_large:\", mask_large[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initially set Size to small, then change roughly half to be large\n",
    "data['Size'] = 'small'\n",
    "data.loc[mask_large, 'Size'] = 'large'\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will soon encounter scikit-learn. Remember now that scikit-learn requires ALL data to be represented numerically.\n",
    "\n",
    "If a feature only has two categories, we can simply create a dummy variable that represents the categories as a binary value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a new Series called IsLarge\n",
    "data['IsLarge'] = data.Size.map({'small': 0, 'large': 1})  # this is new, can you figure out what .map() is doing?\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummying categorical variables with more than two categories\n",
    "Let's create a new feature called Area, and randomly assign observations to be rural, suburban, or urban:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# assign roughly one third of observations to each group\n",
    "nums = np.random.rand(len(data))\n",
    "mask_suburban = (nums > 0.33) & (nums < 0.66)\n",
    "mask_urban = nums > 0.66\n",
    "data['Area'] = 'rural'\n",
    "data.loc[mask_suburban, 'Area'] = 'suburban'\n",
    "data.loc[mask_urban, 'Area'] = 'urban'\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to represent Area numerically, but we can't simply code it as 0=rural, 1=suburban, 2=urban because that would imply an ordered relationship between suburban and urban (and thus urban is somehow \"twice\" the suburban category).\n",
    "\n",
    "Instead, we create another dummy variable:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Common pattern: create multiple dummy variables using get_dummies(), then exclude the first dummy column\n",
    "    my_categorical_var_dummies = pd.get_dummies(my_categorical_var, prefix='Area').iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create three dummy variables using get_dummies, then exclude the first dummy column\n",
    "area_dummies = pd.get_dummies(data.Area, prefix='Area').iloc[:, 1:]\n",
    "\n",
    "# now concatenate the dummy variable columns onto the original DataFrame (axis=0 means rows, axis=1 means columns)\n",
    "data = pd.concat([data, area_dummies], axis=1)\n",
    "data.head()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
